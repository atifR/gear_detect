{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo notebook to detect whether people are using safety gear or not\n",
    "\n",
    "The data is taken from <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision.transforms.v2 as v2\n",
    "import math\n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parametes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Settings ... \n",
      " dataset path \t\t ../Dataset \n",
      " batch_size \t\t 32\n",
      " train_ratio \t\t 0.85 \n",
      " validation ratio \t 0.0 \n",
      " test ratio \t\t 0.15 \n",
      " device \t\t cuda\n"
     ]
    }
   ],
   "source": [
    "dataset_folder  = \"../Dataset\"\n",
    "batch_size = 32\n",
    "train_ratio = 0.85\n",
    "valid_ratio = 0.0\n",
    "test_ratio = 0.15\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "print (f\"Settings ... \\n dataset path \\t\\t {dataset_folder} \\n batch_size \\t\\t {batch_size}\" +\n",
    "       f\"\\n train_ratio \\t\\t {train_ratio} \\n validation ratio \\t {valid_ratio} \\n test ratio \\t\\t {test_ratio} \\n device \\t\\t {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the classes in the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Not Wearing Safety Gear', 'Wearing Safety Gear']\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "class_labels = [name for name in os.listdir(dataset_folder) if not name.startswith(\".DS_Store\")]\n",
    "print(class_labels)\n",
    "num_classes = len(class_labels)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataset from the image folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "transformations = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.RandomHorizontalFlip(),\n",
    "    v2.RandomVerticalFlip(),\n",
    "    v2.RandomResizedCrop(size=(256, 256), antialias=True),\n",
    "    v2.RandomRotation(degrees = (0, 170)),\n",
    "    v2.ToDtype(dtype = torch.float32, scale = True),\n",
    "    v2.Resize(size = (256, 256), antialias = True),\n",
    "    v2.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "dataset = ImageFolder(dataset_folder, transform = transformations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "probe stats from the Image folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes ['Not Wearing Safety Gear', 'Wearing Safety Gear']\n"
     ]
    }
   ],
   "source": [
    "print (f\"classes {dataset.classes}\")\n",
    "d = dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "splitting the dataset <br>\n",
    "this is a small dataset, we ar eonly using train and test dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset 355, train dataset 302, test size 53\n",
      "Lenght of training dataset 302\n",
      "Lenght of test dataset 53\n"
     ]
    }
   ],
   "source": [
    "train_size = math.ceil(len(dataset) * train_ratio)\n",
    "test_szie = math.floor(len(dataset) * test_ratio)\n",
    "print(f\"dataset {len(dataset)}, train dataset {train_size}, test size {test_szie}\")\n",
    "\n",
    "train_dataset, test_dataset = random_split(dataset,[train_size, test_szie])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,shuffle=True,batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset,shuffle=True, batch_size=batch_size,pin_memory=True)\n",
    "\n",
    "print(f\"Lenght of training dataset {len(train_dataloader.dataset)}\")\n",
    "print(f\"Lenght of test dataset {len(test_dataloader.dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try ResNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_net = torchvision.models.resnet50(weights='IMAGENET1K_V1')\n",
    "\n",
    "for param in res_net.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "res_net.fc  = torch.nn.Sequential(\n",
    "    nn.Linear(2048,128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(\n",
    "        in_features=128,\n",
    "        out_features=num_classes\n",
    "    ),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANy other model(s) to evalaute can go here ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_evaluate = res_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(res_net.fc.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model,model_name,criterion,optimier, data_loader,device, num_epochs=0):\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        #loss_batches = 0\n",
    "        loss_epoch=0;\n",
    "        corrects_batches = 0\n",
    "        count = 0\n",
    "        start = time.time()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        data_loading_begin = time.time()\n",
    "        data_loading_time = 0\n",
    "        data_processing_time = 0 \n",
    "        for x,y in data_loader:\n",
    "            \n",
    "            x,y = x.to(device), y.to(device)\n",
    "            data_loading_time += (time.time()-data_loading_begin)\n",
    "            processing_time_begin = time.time()\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs,y)\n",
    "            optimier.zero_grad()\n",
    "            loss.backward()\n",
    "            optimier.step()\n",
    "            data_processing_time += (time.time()-processing_time_begin)\n",
    "            _,preds = torch.max(outputs,1)\n",
    "\n",
    "            correct += (preds == y).sum().item()\n",
    "            total += preds.size(0)\n",
    "            loss_epoch += loss.item()\n",
    "            count += 1\n",
    "            data_loading_begin = time.time()\n",
    "        #epoch_loss = loss_batches / len(data_loader)\n",
    "        epoch_acc = correct / total\n",
    "        print(f\"\\n epoch {epoch} Loss : {(loss_epoch/count):.4f} Accuracy {epoch_acc:.2f}, time : {time.time()-start} secs\")\n",
    "        print(f\"data loading time {data_loading_time} secs, data processing time {data_processing_time} secs\")\n",
    "        if (epoch % 3 == 0 ):\n",
    "          torch.save(model.state_dict(),f\"{model_name}_{epoch:02d}_{epoch_acc:.2f}.h5\")\\\n",
    "          \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " epoch 0 Loss : 0.2938 Accuracy 0.86, time : 16.442638397216797 secs\n",
      "data loading time 15.544307947158813 secs, data processing time 0.2253870964050293 secs\n",
      "\n",
      " epoch 1 Loss : 0.2740 Accuracy 0.86, time : 15.586276054382324 secs\n",
      "data loading time 14.887279748916626 secs, data processing time 0.23354411125183105 secs\n",
      "\n",
      " epoch 2 Loss : 0.2504 Accuracy 0.89, time : 15.689343690872192 secs\n",
      "data loading time 15.03190803527832 secs, data processing time 0.2397916316986084 secs\n",
      "\n",
      " epoch 3 Loss : 0.2521 Accuracy 0.90, time : 16.6470787525177 secs\n",
      "data loading time 15.990078926086426 secs, data processing time 0.25426149368286133 secs\n",
      "\n",
      " epoch 4 Loss : 0.1956 Accuracy 0.92, time : 16.844648838043213 secs\n",
      "data loading time 16.025765657424927 secs, data processing time 0.24703550338745117 secs\n",
      "\n",
      " epoch 5 Loss : 0.2050 Accuracy 0.92, time : 16.114879608154297 secs\n",
      "data loading time 15.459449529647827 secs, data processing time 0.24773955345153809 secs\n",
      "\n",
      " epoch 6 Loss : 0.2704 Accuracy 0.91, time : 15.923333168029785 secs\n",
      "data loading time 15.26256513595581 secs, data processing time 0.23540425300598145 secs\n",
      "\n",
      " epoch 7 Loss : 0.2220 Accuracy 0.91, time : 16.10226559638977 secs\n",
      "data loading time 15.340797424316406 secs, data processing time 0.2407987117767334 secs\n",
      "\n",
      " epoch 8 Loss : 0.2595 Accuracy 0.89, time : 16.365399837493896 secs\n",
      "data loading time 15.70663595199585 secs, data processing time 0.23937773704528809 secs\n",
      "\n",
      " epoch 9 Loss : 0.2299 Accuracy 0.90, time : 16.443122625350952 secs\n",
      "data loading time 15.785131692886353 secs, data processing time 0.2555239200592041 secs\n",
      "\n",
      " epoch 10 Loss : 0.1954 Accuracy 0.93, time : 16.026464462280273 secs\n",
      "data loading time 15.360334396362305 secs, data processing time 0.24238967895507812 secs\n",
      "\n",
      " epoch 11 Loss : 0.1914 Accuracy 0.92, time : 16.198254585266113 secs\n",
      "data loading time 15.535498857498169 secs, data processing time 0.244340181350708 secs\n",
      "\n",
      " epoch 12 Loss : 0.2548 Accuracy 0.88, time : 15.916590690612793 secs\n",
      "data loading time 15.3040931224823 secs, data processing time 0.2324223518371582 secs\n",
      "\n",
      " epoch 13 Loss : 0.1924 Accuracy 0.92, time : 15.915846347808838 secs\n",
      "data loading time 15.293622493743896 secs, data processing time 0.23532938957214355 secs\n",
      "\n",
      " epoch 14 Loss : 0.1848 Accuracy 0.93, time : 16.028977632522583 secs\n",
      "data loading time 15.398159503936768 secs, data processing time 0.27785706520080566 secs\n",
      "\n",
      " epoch 15 Loss : 0.2899 Accuracy 0.86, time : 16.140392303466797 secs\n",
      "data loading time 15.501519203186035 secs, data processing time 0.24219989776611328 secs\n",
      "\n",
      " epoch 16 Loss : 0.1730 Accuracy 0.93, time : 15.938567638397217 secs\n",
      "data loading time 15.280012369155884 secs, data processing time 0.2581319808959961 secs\n",
      "\n",
      " epoch 17 Loss : 0.1881 Accuracy 0.90, time : 15.881161212921143 secs\n",
      "data loading time 15.216241836547852 secs, data processing time 0.24431419372558594 secs\n",
      "\n",
      " epoch 18 Loss : 0.2010 Accuracy 0.91, time : 16.047118663787842 secs\n",
      "data loading time 15.382505416870117 secs, data processing time 0.24420666694641113 secs\n",
      "\n",
      " epoch 19 Loss : 0.2674 Accuracy 0.90, time : 16.163320302963257 secs\n",
      "data loading time 15.403165578842163 secs, data processing time 0.2632875442504883 secs\n",
      "\n",
      " epoch 20 Loss : 0.2338 Accuracy 0.90, time : 15.889306783676147 secs\n",
      "data loading time 15.226064682006836 secs, data processing time 0.24149274826049805 secs\n",
      "\n",
      " epoch 21 Loss : 0.2768 Accuracy 0.87, time : 15.762726783752441 secs\n",
      "data loading time 15.101633548736572 secs, data processing time 0.22839856147766113 secs\n",
      "\n",
      " epoch 22 Loss : 0.1987 Accuracy 0.90, time : 16.05842614173889 secs\n",
      "data loading time 15.21497631072998 secs, data processing time 0.2312614917755127 secs\n",
      "\n",
      " epoch 23 Loss : 0.1454 Accuracy 0.94, time : 15.719184398651123 secs\n",
      "data loading time 15.052546501159668 secs, data processing time 0.24126577377319336 secs\n",
      "\n",
      " epoch 24 Loss : 0.1555 Accuracy 0.93, time : 16.50254225730896 secs\n",
      "data loading time 15.839208126068115 secs, data processing time 0.25362086296081543 secs\n",
      "\n",
      " epoch 25 Loss : 0.1413 Accuracy 0.94, time : 16.34808850288391 secs\n",
      "data loading time 15.649415254592896 secs, data processing time 0.2515535354614258 secs\n",
      "\n",
      " epoch 26 Loss : 0.1684 Accuracy 0.94, time : 16.427926778793335 secs\n",
      "data loading time 15.765828371047974 secs, data processing time 0.25130462646484375 secs\n",
      "\n",
      " epoch 27 Loss : 0.2762 Accuracy 0.89, time : 16.44376301765442 secs\n",
      "data loading time 15.764789342880249 secs, data processing time 0.25447654724121094 secs\n",
      "\n",
      " epoch 28 Loss : 0.2086 Accuracy 0.91, time : 16.35614848136902 secs\n",
      "data loading time 15.555430173873901 secs, data processing time 0.2452101707458496 secs\n",
      "\n",
      " epoch 29 Loss : 0.2126 Accuracy 0.89, time : 15.672962427139282 secs\n",
      "data loading time 15.018321514129639 secs, data processing time 0.2326669692993164 secs\n"
     ]
    }
   ],
   "source": [
    "train_model(model_to_evaluate,\"res_net\",criterion=criterion, optimier=optimizer,\n",
    "            data_loader=train_dataloader, device=device, num_epochs=30)\n",
    "\n",
    "torch.save(model_to_evaluate.state_dict(),'resNet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(loader, model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            correct += (predictions == y).sum().item()\n",
    "            total += predictions.size(0)\n",
    "    model.train()\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy is 95.03311258278146\n",
      "Testing Accuracy is 86.79245283018868\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Accuracy is {calculate_accuracy(train_dataloader, res_net)*100}\")\n",
    "\n",
    "print(f\"Testing Accuracy is {calculate_accuracy(test_dataloader, res_net)*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
